{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3e9044",
   "metadata": {},
   "source": [
    "# English quenya translation using a transformer - Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372476ce",
   "metadata": {},
   "source": [
    "## Main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd796ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import nltk\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from model import Transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"https://eldamo.org/content/phrase-indexes/phrases-q.html\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce8c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c975409",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_english = soup.select('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8040bb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A anamelda na ar ilyan  “A is dearest of all”\\n               '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_english[50].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394c474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quenya_sentences =[]\n",
    "for row in rows_english:\n",
    "    quenya_sentences.append(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f53dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = quenya_sentences[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f1c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_english = []\n",
    "sentences_quenya = []\n",
    "for sentence in sentences:\n",
    "    compteur = 0\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]==\"“\":\n",
    "            beginning = i+1\n",
    "        if sentence[i]==\"”\":\n",
    "            ending = i\n",
    "            last_ending = ending\n",
    "            compteur+=1\n",
    "            sentences_english.append(sentence[beginning:ending])\n",
    "            if compteur==1:\n",
    "                sentences_quenya.append(sentence[:beginning])\n",
    "            else:\n",
    "                sentences_quenya.append(sentence[last_ending:beginning])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40619f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a07e57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_quenya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453826ac",
   "metadata": {},
   "source": [
    "## Poems & prayers found on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034e305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = [\"https://eldamo.org/content/words/word-2555725393.html\", \"https://eldamo.org/content/words/word-2245526111.html\",\n",
    "            \"https://eldamo.org/content/words/word-671674147.html\", \"https://eldamo.org/content/words/word-311699583.html\",\n",
    "            \"https://eldamo.org/content/words/word-2920398593.html\", \"https://eldamo.org/content/words/word-3295893985.html\",\n",
    "            \"https://eldamo.org/content/words/word-2124111669.html\", \"https://eldamo.org/content/words/word-4161205007.html\",\n",
    "            \"https://eldamo.org/content/words/word-436003197.html\", \"https://eldamo.org/content/words/word-2774144071.html\",\n",
    "            \"https://eldamo.org/content/words/word-3330342599.html\", \"https://eldamo.org/content/words/word-1216507117.html\",\n",
    "            \"https://eldamo.org/content/words/word-2721399773.html\", \"https://eldamo.org/content/words/word-1235857611.html\"]\n",
    "for url in list_url:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    rows_english = soup.select('td')\n",
    "    for i in range(0,len(rows_english)):\n",
    "        if i%2==0:\n",
    "            sentences_quenya.append(rows_english[i].text)\n",
    "        else:\n",
    "            sentences_english.append(rows_english[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a17be11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bdb5322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_quenya)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d85d4",
   "metadata": {},
   "source": [
    "## Dictionary pulled from Eldamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa9d46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://eldamo.org/content/vocabulary-indexes/vocabulary-words-nq.html?neo\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "rows = soup.select('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81348d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for row in rows:\n",
    "    words.append(row.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b436769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_english = []\n",
    "words_quenya = []\n",
    "for word in words:\n",
    "    compteur=0\n",
    "    for i in range(len(word)):\n",
    "        if ((word[i]==\" \") | (word[i]==\"-\"))&(compteur==0)&(i!=0):\n",
    "            ending_quenya = i\n",
    "            words_quenya.append(word[:ending_quenya])\n",
    "            compteur+=1\n",
    "        if word[i]==\"“\":\n",
    "            beginning = i+1 \n",
    "        if word[i]==\"”\":\n",
    "            ending = i\n",
    "            words_english.append(word[beginning:ending])\n",
    "            break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d03f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4921"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eed2971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4921"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_quenya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20167db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_english = np.concatenate([sentences_english, words_english])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa744ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_quenya = np.concatenate([sentences_quenya, words_quenya])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abee0d4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_english = []\n",
    "list_quenya = []\n",
    "for sentence in sentences_english:\n",
    "    list_english.append(list(sentence))\n",
    "for sentence in sentences_quenya:\n",
    "    list_quenya.append(list(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b1f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "for i in range(len(sentences_english)):\n",
    "    if len(list_english[i])>m: \n",
    "        m = len(list_english[i])\n",
    "    if len(list_quenya[i])>m:\n",
    "        m = len(list_quenya[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27afc9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cb443",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "569110e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char2index = {}\n",
    "index2char = {}\n",
    "counter = 1\n",
    "for i in range(len(sentences_english)):\n",
    "    sent_english = sentences_english[i]\n",
    "    sent_quenya = sentences_quenya[i]\n",
    "    for w in sent_english:\n",
    "        if w not in char2index:\n",
    "            counter+=1\n",
    "            char2index[w] = counter\n",
    "            index2char[counter] = w\n",
    "    for w in sent_quenya:\n",
    "        if w not in char2index:\n",
    "            counter+=1\n",
    "            char2index[w] = counter\n",
    "            index2char[counter] = w\n",
    "char2index['<EOS>'] = counter+1\n",
    "index2char[counter+1] = '<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "669f3998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 147)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en = np.zeros([len(list_english), m+1])\n",
    "data_quenya = np.zeros([len(list_english), m+1])\n",
    "data_quenya.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db10384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_english)):\n",
    "    for j in range(len(list_english[i])):\n",
    "        data_en[i,j] = char2index[list_english[i][j]]\n",
    "    data_en[i,len(list_english[i])] = char2index['<EOS>']\n",
    "    for j in range(len(list_quenya[i])):\n",
    "        data_quenya[i,j] = char2index[list_quenya[i][j]]\n",
    "    data_quenya[i,len(list_quenya[i])] = char2index['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8729a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fc6a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "for d in range(len(data_quenya)):\n",
    "    if np.array_equal(a,data_quenya[d]):\n",
    "        L.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b32c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en = np.delete(data_en,L,0)\n",
    "data_quenya = np.delete(data_quenya,L,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a25883ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 147)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_quenya.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a0db0",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11620b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a295e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_SIZE = len(char2index)+2\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 4\n",
    "HID_DIM = 1024\n",
    "BATCH_SIZE = 40\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "NUM_DECODER_LAYERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4a32f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, HID_DIM, 0.01, VOC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbacac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52ce275e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_train, en_test, qu_train, qu_test = train_test_split(data_en, data_quenya, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bf8a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train = torch.Tensor(en_train).long()\n",
    "en_test = torch.Tensor(en_test).long()\n",
    "qu_train = torch.Tensor(qu_train).long()\n",
    "qu_test = torch.Tensor(qu_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3233062",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(en_train, qu_train)\n",
    "test_dataset = TensorDataset(en_test, qu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac6616f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16def618",
   "metadata": {},
   "source": [
    "## Masks creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eebb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positionalEncoding(length, embed_dim):\n",
    "    angles = np.array([[pos/10000**(2*(i//2)) for i in range(embed_dim)] for pos in range(length)])\n",
    "    pos_encoding = np.zeros((length, embed_dim))\n",
    "    pos_encoding[:,0::2] = np.sin(angles[:,0::2])\n",
    "    pos_encoding[:,1::2] = np.cos(angles[:,1::2])\n",
    "    return torch.from_numpy(pos_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e982ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1).to(torch.bool)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52e6bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_mask(x):\n",
    "    return x==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05af6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = positionalEncoding(m+1, EMB_SIZE).to(DEVICE)\n",
    "attn_mask = create_look_ahead_mask(m+1).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c7a5d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6cb417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [5/112], Loss: 4.7412\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "transformer.train()\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "torch.autograd.set_detect_anomaly(True) \n",
    "for epoch in range(num_epochs):\n",
    "    # Iterate over the batches in the train_dataloader\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # Get the batch of input sentences and labels\n",
    "        sentences = batch[0].to(DEVICE)\n",
    "        labels = batch[1].to(DEVICE)\n",
    "        src_padding_mask = padding_mask(sentences).to(DEVICE)\n",
    "        tgt_padding_mask = padding_mask(labels).to(DEVICE)\n",
    "        # Reset the gradients\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = transformer(sentences, labels, src_padding_mask, tgt_padding_mask, attn_mask, pos_encoding)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.view(-1,VOC_SIZE,m+1), labels)\n",
    "        torch.nn.utils.clip_grad_norm_(transformer.parameters(), 0.5)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss every 100 batches\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, batch_idx+1, len(train_dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c4b94",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90fbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer.train(mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = np.zeros(m+1)\n",
    "output_sentence = np.zeros(m+1)\n",
    "generated_sentence = []\n",
    "my_sentence = \"This is a test sentence\"\n",
    "for i in range(len(my_sentence)):\n",
    "    input_sentence[i] = char2index[my_sentence[i]]\n",
    "input_sentence[len(my_sentence)]=char2index['<EOS>']\n",
    "input_sentence = torch.Tensor(input_sentence).long().to(DEVICE)\n",
    "output_sentence = torch.Tensor(output_sentence).long().to(DEVICE)\n",
    "output_sentence[0]=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66828ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_padding_mask = padding_mask(input_sentence)\n",
    "s=1\n",
    "generated_letter = 6\n",
    "while (len(generated_sentence))<10 and (generated_letter!=char2index['<EOS>']):\n",
    "    tgt_padding_mask = padding_mask(output_sentence)\n",
    "    tgt_padding_mask[0]=False\n",
    "    print(output_sentence)\n",
    "    last_output = transformer(input_sentence, output_sentence, src_padding_mask, tgt_padding_mask, attn_mask, pos_encoding)\n",
    "    last_output = torch.argmax(last_output, -1)\n",
    "    generated_letter = last_output[s]\n",
    "    generated_sentence.append(generated_letter)\n",
    "    output_sentence[s] = generated_letter\n",
    "    s+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ef486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "L=[]\n",
    "for c in output_sentence:\n",
    "    if c.item()!=0:\n",
    "        L.append(index2char[c.item()])\n",
    "print(L)\n",
    "''.join(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f21072",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index[' ']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
